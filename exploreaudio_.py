# -*- coding: utf-8 -*-
"""ExploreAudio .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ET0pFyxafjP6O3IU_QeWf6V5gtBEE0TL
"""

pip install datasets

pip install gradio

from datasets import load_dataset

minds = load_dataset("PolyAI/minds14", "en-AU", split="train")

minds

minds["transcription"][5]

minds["intent_class"][5]

minds[100]

minds[70]

id2label = minds.features["intent_class"].int2str
id2label(minds[70]["intent_class"])



column_removed = ["lang_id", "english_transcription"]
minds = minds.remove_columns(column_removed)

minds

import gradio as gr


def generate_audio():
    example = minds.shuffle()[0]
    audio = example["audio"]
    return (
        audio["sampling_rate"],
        audio["array"],
    ), id2label(example["intent_class"])


with gr.Blocks() as demo:
    with gr.Column():
        for _ in range(4):
            audio, label = generate_audio()
            output = gr.Audio(audio, label=label)

demo.launch(debug=True)

"""# waveform"""

minds

minds["audio"][0]["array"]

minds["audio"][0]["sampling_rate"]

example = minds.shuffle()[0]

example

array = example["audio"]["array"]
sampling_rate = example["audio"]["sampling_rate"]

"""#show amplitude"""

import librosa
import matplotlib.pyplot as plt
import seaborn as sns
import librosa.display

# plt.figure().set_figwidth(12)

librosa.display.waveshow(array,sr =sampling_rate)

def show_audio(array,sampling_rate):
    plt.figure().set_figwidth(12)
    librosa.display.waveshow(array,sr =sampling_rate)
    plt.show()

show_audio(array,sampling_rate)

"""# Preprocessing an audio dataset

* Resampling the audio data
* Filtering the dataset
* Converting audio data to modelâ€™s expected input
"""

from datasets import Audio

minds = minds.cast_column("audio",Audio(sampling_rate=16000))

minds[0]

"""# it's changed"""

MAX_DURATION_IN_SECONDS = 20.0

def filter_audio(input_length):
  return input_length <= MAX_DURATION_IN_SECONDS

new_column = [librosa.get_duration(path=x) for x in minds["path"]]
minds = minds.add_column("duration",new_column)

minds = minds.filter(filter_audio,input_columns=["duration"])
minds = minds.remove_columns(["duration"])
minds

"""### Minds it converted from   num_rows: 654 into num_rows: 624"""

from transformers import WhisperFeatureExtractor
feature_extracore = WhisperFeatureExtractor.from_pretrained("openai/whisper-small")

def prepare_data(example):
  audio = example["audio"]
  input_features = feature_extracore(
      audio["array"],sampling_rate=audio["sampling_rate"],padding = True
  )
  return input_features

minds = minds.map(prepare_data)

minds

"""# visualize it for one of the examples in the minds dataset:"""

import numpy as np

example = minds[0]
input_feature = example["input_features"]


plt.figure().set_figwidth(12)

librosa.display.specshow(
    np.asarray(input_feature[0],
              ),
    x_axis="time",
    y_axis="mel",
    sr = feature_extracore.sampling_rate,
    hop_length= feature_extracore.hop_length

)
plt.colorbar()

# librosa.get_duration(path=example["path"])

"""# how deal with big dataset audio data
### you can use `Streaming mode`
"""

minds_st_mode = load_dataset("PolyAI/minds14","en-US",streaming=True)

minds_st_mode

minds_st_mode["train"][0]

next(iter(minds_st_mode["train"]))

minds_st_mode["train"]["path"].take(2)

